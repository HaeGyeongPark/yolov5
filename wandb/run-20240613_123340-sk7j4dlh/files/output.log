Overriding model.yaml nc=4 with nc=15
                 from  n    params  module                                  arguments
  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]
  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]
  2                -1  1      4800  models.common.C3                        [32, 32, 1]
  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]
  4                -1  2     29184  models.common.C3                        [64, 64, 2]
  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]
  6                -1  3    156928  models.common.C3                        [128, 128, 3]
  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]
  8                -1  1    296448  models.common.C3                        [256, 256, 1]
  9                -1  1    164608  models.common.SPPF                      [256, 256, 5]
 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 12           [-1, 6]  1         0  models.common.Concat                    [1]
 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]
 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 16           [-1, 4]  1         0  models.common.Concat                    [1]
 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]
 18                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]
 19          [-1, 14]  1         0  models.common.Concat                    [1]
 20                -1  1     74496  models.common.C3                        [128, 128, 1, False]
 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]
 22          [-1, 10]  1         0  models.common.Concat                    [1]
 23                -1  1    296448  models.common.C3                        [256, 256, 1, False]
 24      [17, 20, 23]  1      9020  models.yolo.Detect                      [15, [[16, 30], [62, 45], [156, 198]], [64, 128, 256]]
YOLOv5n_nuscenes summary: 214 layers, 1766172 parameters, 1766172 gradients, 4.2 GFLOPs
Transferred 342/349 items from yolov5n.pt
[34m[1mAMP: [39m[22mchecks passed âœ…
[34m[1moptimizer:[39m[22m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias
[34m[1mtrain: [39m[22mScanning /home/yolov5/AUE8088-PA2/datasets/nuscenes/train.cache... 28130 images, 1425 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28130/28130 [00:00<?, ?it/s]
[34m[1mval: [39m[22mScanning /home/yolov5/AUE8088-PA2/datasets/nuscenes/val.cache... 6019 images, 257 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6019/6019 [00:00<?, ?it/s]
[34m[1mval: [39m[22mWARNING âš ï¸ datasets/nuscenes/val/images/1220f9a205ae44418fcce91722e1e601.png: 1 duplicate labels removed
Plotting labels to runs/train/yolov5n8/labels.jpg...
Image sizes 416 train, 416 val
Using 16 dataloader workers
Logging results to [1mruns/train/yolov5n8
Starting training for 200 epochs...
      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size















      0/199       2.9G    0.08502    0.03081    0.02692        534        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 440/440 [00:31<00:00, 13.76it/s]



                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:08<00:05,  3.45it/s]
Traceback (most recent call last):
  File "/home/yolov5/AUE8088-PA2/train_simple.py", line 485, in <module>
    main(opt)
  File "/home/yolov5/AUE8088-PA2/train_simple.py", line 480, in main
    train(opt.hyp, opt, device, callbacks)
  File "/home/yolov5/AUE8088-PA2/train_simple.py", line 327, in train
    results, maps, _ = validate.run(
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/yolov5/AUE8088-PA2/val.py", line 274, in run
    scale_boxes(im[si].shape[1:], tbox, shape, shapes[si][1])  # native-space labels
  File "/home/yolov5/AUE8088-PA2/utils/general.py", line 962, in scale_boxes
    clip_boxes(boxes, img0_shape)
  File "/home/yolov5/AUE8088-PA2/utils/general.py", line 985, in clip_boxes
    def clip_boxes(boxes, shape):
KeyboardInterrupt